---
title: "Q5 Cleaned"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(glmnet)
```

```{r}
test.documents = read.csv("../data/ReutersC50/test_documents.csv", header = TRUE, row.names = 1)
test.bigrams = read.csv("../data/ReutersC50/test_bigrams.csv", header = TRUE, row.names = 1)

train.documents = read.csv("../data/ReutersC50/train_documents.csv", header = TRUE, row.names = 1)
train.bigrams = read.csv("../data/ReutersC50/train_bigrams.csv", header = TRUE, row.names = 1)
```

```{r}
Z = train.bigrams/rowSums(train.bigrams)
Z = na.omit(Z)
```

```{r}
pc2 = prcomp(Z, scale=TRUE, rank=5)
loadings = pc2$rotation
scores = pc2$x
```

```{r}
library(ggplot2)
qplot(scores[,1], scores[,2], xlab='Component 1', ylab='Component 2')
```


Start here:

```{r}
N = nrow(train.bigrams)
D = ncol(train.bigrams)

#remove 0 row sums
train.bigrams = train.bigrams[rowSums(train.bigrams) != 0,]
train.documents = train.documents[row.names(train.bigrams),]
#remove 0 col sums
train.bigrams = train.bigrams[,colSums(train.bigrams) != 0]

# TF weights
TF_mat = train.bigrams/rowSums(train.bigrams)
# IDF weights
IDF_vec = log(1 + N/colSums(train.bigrams > 0))
# TF-IDF weights:
# use sweep to multiply the columns (margin = 2) by the IDF weights
TFIDF_mat = sweep(TF_mat, MARGIN=2, STATS=IDF_vec, FUN="*")  
```

```{r}
# PCA on the TF-IDF weights
pca = prcomp(TFIDF_mat, scale=TRUE)
pve = summary(pca)$importance[3,]
plot(pve)  # not much of an elbow
```

```{r}
X = pca$x[,1:100]
y = {train.documents$author}
```




```{r}
out1 = cv.glmnet(X, y, family='multinomial', type.measure="class")
```

```{r}
cat('Training Accuracy = ', 1- min(out1$cvm))
```

```{r}
# Choose lambda to minimize CV error
lambda_hat = out1$lambda.min
```

```{r}
lambda_hat
```





Past here doesn't work!


```{r}
#this should havea lambda arguement
glm1 = glmnet(X, y, family='multinomial')
```



Now do the PCA for test set and predict:

```{r}
N = nrow(test.bigrams)
D = ncol(test.bigrams)

#remove 0 row sums
test.bigrams = test.bigrams[rowSums(test.bigrams) != 0,]
test.documents = test.documents[row.names(test.bigrams),]
#remove 0 col sums
test.bigrams = test.bigrams[,colSums(test.bigrams) != 0]

# TF weights
TF_mat = test.bigrams/rowSums(test.bigrams)
# IDF weights
IDF_vec = log(1 + N/colSums(test.bigrams > 0))
# TF-IDF weights:
# use sweep to multiply the columns (margin = 2) by the IDF weights
TFIDF_mat = sweep(TF_mat, MARGIN=2, STATS=IDF_vec, FUN="*")  

# PCA on the TF-IDF weights
pca = prcomp(TFIDF_mat, scale=TRUE)
pve = summary(pca)$importance[3,]
plot(pve)  # not much of an elbow

Xtest = pca$x[,1:100]
ytest = {test.documents$author}


```

```{r}
pred_author <- predict(glm1, newx = Xtest,type = 'response')
```



```{r}
summary(glm1$lambda)

```


















